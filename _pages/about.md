---
layout: about
title: About
permalink: /
subtitle:

profile:
  align: right
  image: prof_pic.jpg
  image_circular: true # crops the image to make it circular
  more_info: >
    

news: true # includes a list of news items
latest_posts: false # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

Welcome! I'm a PhD candidate at [Princeton](https://www.princeton.edu/), where I work with [Anirudha Majumdar](https://mae.princeton.edu/people/faculty/majumdar) 
and [Naomi Leonard](https://naomi.princeton.edu/research-group/) on [robotics](https://robo.princeton.edu/). During my 
PhD I've spent time at [Toyota Research Institute](https://www.tri.global/) working on [human-interactive driving](https://www.tri.global/our-work/human-interactive-driving). 

I design algorithms that enable robots to intelligently interact with and learn from people. One of my key interests is [value alignment](https://en.wikipedia.org/wiki/AI_alignment) from an [optimal control](https://en.wikipedia.org/wiki/Optimal_control) perspective: AI systems 
may offer strong performance but lack nuance in their understanding of intuitive and safe behaviors. To bridge this gap, I am working to enable robots to closely mimic people through [imitation](https://en.wikipedia.org/wiki/Imitative_learning) while optimizing their long-term behavior for safety and robustness.  My long-term goal is to enable robots to recognize their own uncertainty and continuously adjust their strategies through [feedback](https://en.wikipedia.org/wiki/Feedback) during training, evaluation, and deployment. 

`jlidard` at `princeton` dot `edu`

[Google Scholar](https://scholar.google.com/citations?user=tdNDbF8AAAAJ&hl=en) &nbsp; [Github](https://github.com/jlidard) &nbsp; [LinkedIn](https://www.linkedin.com/in/lidard/) 